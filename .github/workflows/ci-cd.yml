# .github/workflows/ci-cd.yml
# This is the final, correct version that deploys code via S3.

name: Build and Deploy Lambdas via S3

on:
  # This workflow runs on every push to the 'main' branch
  push:
    branches:
    - main

  # This allows you to run the workflow manually from the Actions tab
  workflow_dispatch:


jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code from repository
      uses: actions/checkout@v3

    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_KEY }}
        aws-region: us-east-1 # Make sure this is your correct AWS region

    - name: Set up Python environment
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install Zip utility (required for packaging)
      run: sudo apt-get install -y zip

    - name: Build and Upload Lambda Layer to S3
      run: |
        echo "--- Building Lambda Layer ---"
        # AWS Layers need dependencies in a specific folder structure
        mkdir -p build/python
        pip install -r src/lambda_layer/requirements.txt -t build/python

        # Zip the contents of the 'build' directory
        cd build
        zip -r ../ml_libraries_layer.zip .
        cd ..

        echo "Uploading layer zip to S3..."
        # This uploads the layer to a specific path in your S3 bucket
        aws s3 cp ml_libraries_layer.zip s3://aiops-self-healing-ml-artifacts-ae5e41cffb13299d/lambda-layers/ml_libraries_layer.zip

    - name: Build and Upload Lambda Functions to S3, then Update Functions
      run: |
        # Navigate into the directory containing all lambda function folders
        cd src/lambda_functions

        # Loop through each function directory (e.g., anomaly_detection)
        for lambda_dir in */ ; do
          LAMBDA_NAME=${lambda_dir%/} # Get the clean directory name
          echo "--- Processing Lambda: $LAMBDA_NAME ---"
          
          # Create a temporary package directory
          mkdir -p package
          
          # Install dependencies if a requirements.txt file exists and is not empty
          if [ -f "$LAMBDA_NAME/requirements.txt" ] && [ -s "$LAMBDA_NAME/requirements.txt" ]; then
            pip install -r "$LAMBDA_NAME/requirements.txt" -t "package/"
          fi
          
          # Copy the function's code into the package directory
          cp "$LAMBDA_NAME/app.py" "package/"
          
          # Zip the contents of the package directory
          (cd package && zip -r ../${LAMBDA_NAME}.zip .)
          
          echo "Uploading $LAMBDA_NAME function to S3..."
          # Upload the function's zip file to a specific path in S3
          aws s3 cp ${LAMBDA_NAME}.zip s3://aiops-self-healing-ml-artifacts-ae5e41cffb13299d/lambda-functions/${LAMBDA_NAME}.zip

          # This command tells AWS Lambda to deploy the new code from S3
          echo "Updating Lambda function code for $LAMBDA_NAME from S3..."
          aws lambda update-function-code \
            --function-name aiops-self-healing-${LAMBDA_NAME//_/-} \
            --s3-bucket aiops-self-healing-ml-artifacts-ae5e41cffb13299d \
            --s3-key "lambda-functions/${LAMBDA_NAME}.zip"
          
          # Clean up temporary files for the next loop
          rm -rf package
          rm ${LAMBDA_NAME}.zip
        done
